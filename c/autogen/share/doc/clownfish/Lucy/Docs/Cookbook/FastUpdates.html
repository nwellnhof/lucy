<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<!--
***********************************************

!!!! DO NOT EDIT !!!!

This file was auto-generated by cfc.

***********************************************

Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to You under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
<meta name="viewport" content="width=device-width" />
<title>Lucy::Docs::Cookbook::FastUpdates</title>
<style type="text/css">
body {
    max-width: 48em;
    font: 0.85em/1.4 sans-serif;
}
a {
    color: #23b;
}
table {
    border-collapse: collapse;
}
td {
    padding: 0;
}
td.label {
    padding-right: 2em;
    font-weight: bold;
}
dt {
    font-weight: bold;
}
pre {
    border: 1px solid #ccc;
    padding: 0.2em 0.4em;
    background: #f6f6f6;
    font-size: 0.92em;
}
pre a {
    text-decoration: none;
}
pre, code {
    font-family: "Consolas", "Menlo", monospace;
}
span.prefix, span.comment {
    color: #888;
}
</style>
</head>
<body>
<h1>Near real-time index updates</h1>
<p>While index updates are fast on average, worst-case update performance may be
significantly slower.  To make index updates consistently quick, we must
manually intervene to control the process of index segment consolidation.</p>
<h2>The problem</h2>
<p>Ordinarily, modifying an index is cheap. New data is added to new segments,
and the time to write a new segment scales more or less linearly with the
number of documents added during the indexing session.</p>
<p>Deletions are also cheap most of the time, because we don’t remove documents
immediately but instead mark them as deleted, and adding the deletion mark is
cheap.</p>
<p>However, as new segments are added and the deletion rate for existing segments
increases, search-time performance slowly begins to degrade.  At some point,
it becomes necessary to consolidate existing segments, rewriting their data
into a new segment.</p>
<p>If the recycled segments are small, the time it takes to rewrite them may not
be significant.  Every once in a while, though, a large amount of data must be
rewritten.</p>
<h2>Procrastinating and playing catch-up</h2>
<p>The simplest way to force fast index updates is to avoid rewriting anything.</p>
<p>Indexer relies upon <a href="../../../Lucy/Index/IndexManager.html">IndexManager</a>’s
<a href="../../../Lucy/Index/IndexManager.html#func_Recycle">Recycle()</a> method to tell it which segments should
be consolidated.  If we subclass IndexManager and override the method so that
it always returns an empty array, we get consistently quick performance:</p>
<pre><code class="language-c">Vector*
NoMergeManager_Recycle_IMP(IndexManager *self, PolyReader *reader,
                           DeletionsWriter *del_writer, int64_t cutoff,
                           bool optimize) {
    return Vec_new(0);
}

void
do_index(Obj *index) {
    CFCClass *klass = Class_singleton(&quot;NoMergeManager&quot;, INDEXMANAGER);
    Class_Override(klass, (cfish_method_t)NoMergeManager_Recycle_IMP,
                   LUCY_IndexManager_Recycle_OFFSET);

    IndexManager *manager = (IndexManager*)Class_Make_Obj(klass);
    IxManager_init(manager, NULL, NULL);

    Indexer *indexer = Indexer_new(NULL, index, manager, 0);
    ...
    Indexer_Commit(indexer);

    DECREF(indexer);
    DECREF(manager);
}
</code></pre>
<p>However, we can’t procrastinate forever.  Eventually, we’ll have to run an
ordinary, uncontrolled indexing session, potentially triggering a large
rewrite of lots of small and/or degraded segments:</p>
<pre><code class="language-c">void
do_index(Obj *index) {
    Indexer *indexer = Indexer_new(NULL, index, NULL /* manager */, 0);
    ...
    Indexer_Commit(indexer);
    DECREF(indexer);
}
</code></pre>
<h2>Acceptable worst-case update time, slower degradation</h2>
<p>Never merging anything at all in the main indexing process is probably
overkill.  Small segments are relatively cheap to merge; we just need to guard
against the big rewrites.</p>
<p>Setting a ceiling on the number of documents in the segments to be recycled
allows us to avoid a mass proliferation of tiny, single-document segments,
while still offering decent worst-case update speed:</p>
<pre><code class="language-c">Vector*
LightMergeManager_Recycle_IMP(IndexManager *self, PolyReader *reader,
                              DeletionsWriter *del_writer, int64_t cutoff,
                              bool optimize) {
    IndexManager_Recycle_t super_recycle
        = SUPER_METHOD_PTR(IndexManager, LUCY_IndexManager_Recycle);
    Vector *seg_readers = super_recycle(self, reader, del_writer, cutoff,
                                        optimize);
    Vector *small_segments = Vec_new(0);

    for (size_t i = 0, max = Vec_Get_Size(seg_readers); i &lt; max; i++) {
        SegReader *seg_reader = (SegReader*)Vec_Fetch(seg_readers, i);

        if (SegReader_Doc_Max(seg_reader) &lt; 10) {
            Vec_Push(small_segments, INCREF(seg_reader));
        }
    }

    DECREF(seg_readers);
    return small_segments;
}
</code></pre>
<p>However, we still have to consolidate every once in a while, and while that
happens content updates will be locked out.</p>
<h2>Background merging</h2>
<p>If it’s not acceptable to lock out updates while the index consolidation
process runs, the alternative is to move the consolidation process out of
band, using <a href="../../../Lucy/Index/BackgroundMerger.html">BackgroundMerger</a>.</p>
<p>It’s never safe to have more than one Indexer attempting to modify the content
of an index at the same time, but a BackgroundMerger and an Indexer can
operate simultaneously:</p>
<pre><code class="language-c">typedef struct {
    Obj *index;
    Doc *doc;
} Context;

static void
S_index_doc(void *arg) {
    Context *ctx = (Context*)arg;

    CFCClass *klass = Class_singleton(&quot;LightMergeManager&quot;, INDEXMANAGER);
    Class_Override(klass, (cfish_method_t)LightMergeManager_Recycle_IMP,
                   LUCY_IndexManager_Recycle_OFFSET);

    IndexManager *manager = (IndexManager*)Class_Make_Obj(klass);
    IxManager_init(manager, NULL, NULL);

    Indexer *indexer = Indexer_new(NULL, ctx-&gt;index, manager, 0);
    Indexer_Add_Doc(indexer, ctx-&gt;doc, 1.0);
    Indexer_Commit(indexer);

    DECREF(indexer);
    DECREF(manager);
}

void indexing_process(Obj *index, Doc *doc) {
    Context ctx;
    ctx.index = index;
    ctx.doc = doc;

    for (int i = 0; i &lt; max_retries; i++) {
        Err *err = Err_trap(S_index_doc, &amp;ctx);
        if (!err) { break; }
        if (!Err_is_a(err, LOCKERR)) {
            RETHROW(err);
        }
        WARN(&quot;Couldn't get lock (%d retries)&quot;, i);
        DECREF(err);
    }
}

void
background_merge_process(Obj *index) {
    IndexManager *manager = IxManager_new(NULL, NULL);
    IxManager_Set_Write_Lock_Timeout(manager, 60000);

    BackgroundMerger bg_merger = BGMerger_new(index, manager);
    BGMerger_Commit(bg_merger);

    DECREF(bg_merger);
    DECREF(manager);
}
</code></pre>
<p>The exception handling code becomes useful once you have more than one index
modification process happening simultaneously.  By default, Indexer tries
several times to acquire a write lock over the span of one second, then holds
it until <a href="../../../Lucy/Index/Indexer.html#func_Commit">Commit()</a> completes.  BackgroundMerger handles
most of its work
without the write lock, but it does need it briefly once at the beginning and
once again near the end.  Under normal loads, the internal retry logic will
resolve conflicts, but if it’s not acceptable to miss an insert, you probably
want to catch <a href="../../../Lucy/Store/LockErr.html">LockErr</a> exceptions thrown by Indexer.  In
contrast, a LockErr from BackgroundMerger probably just needs to be logged.</p>
</body>
</html>
